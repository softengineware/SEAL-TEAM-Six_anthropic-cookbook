{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ðŸ”± SEAL TEAM SIX: EXTENDED THINKING OPERATIONS ðŸ”±\n\n## ðŸŽ¯ MISSION BRIEFING: CLAUDE 3.7 SONNET EXTENDED THINKING\n\n**OPERATION**: DEEP COGNITIVE WARFARE  \n**CLASSIFICATION**: TACTICAL TRAINING  \n**OBJECTIVE**: Master Claude's extended thinking capabilities for complex problem-solving operations\n\n## ðŸ“‹ TACTICAL TABLE OF CONTENTS\n- [ðŸ› ï¸ Equipment Setup](#setup)\n- [âš¡ Basic Combat Example](#basic-example)\n- [ðŸ“¡ Streaming Intelligence Operations](#streaming-with-extended-thinking)\n- [ðŸ“Š Resource Management & Token Warfare](#token-counting-and-context-window-management)\n- [ðŸ”’ Classified Thinking Operations](#understanding-redacted-thinking-blocks)\n- [ðŸš¨ Emergency Protocols & Error Handling](#handling-error-cases)\n\n## ðŸŽ–ï¸ OPERATIONAL OVERVIEW\n\nExtended thinking transforms Claude 3.7 Sonnet into an elite reasoning operative, providing:\n- **ENHANCED COGNITION**: Step-by-step tactical analysis\n- **TRANSPARENCY**: Full visibility into operational thinking\n- **PRECISION**: Complex problem decomposition and solution\n\nWhen activated, Claude creates `thinking` content blocks revealing internal reasoning processes before delivering the final tactical response. This is your window into the AI's strategic mind.\n\n**INTEL SOURCE**: [Extended Thinking Documentation](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking)\n\n---\n*\"In the battlefield of complex reasoning, extended thinking is our force multiplier.\"*",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": "## ðŸ› ï¸ EQUIPMENT SETUP & WEAPONS CHECK\n\n**MISSION**: Initialize combat environment and verify all systems operational\n\n**REQUIRED ARSENAL**:\n- Python 3.8+ (Primary weapon system)\n- Anthropic SDK (Communication protocol)\n- API Key (Security clearance)\n- Terminal access (Command center)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": "import anthropic\nimport os\n\n# ðŸ” SECURE YOUR CREDENTIALS - OPSEC CRITICAL\n# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key-here\"\n\n# ðŸŽ¯ INITIALIZE COMBAT SYSTEMS\nclient = anthropic.Anthropic()\n\n# ðŸ›¡ï¸ SEAL TEAM SIX TACTICAL UTILITIES\ndef print_thinking_response(response):\n    \"\"\"\n    SEAL Team Six Response Analysis Protocol\n    - Extracts and displays thinking operations\n    - Maintains operational security on sensitive data\n    \"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"ðŸ”± TACTICAL RESPONSE ANALYSIS ðŸ”±\")\n    print(\"=\"*60)\n    \n    for block in response.content:\n        if block.type == \"thinking\":\n            print(\"\\nðŸ§  COGNITIVE OPERATIONS DETECTED:\")\n            print(\"-\" * 50)\n            # Tactical truncation for operational efficiency\n            thinking_preview = block.thinking[:500] + \"...\" if len(block.thinking) > 500 else block.thinking\n            print(thinking_preview)\n            print(f\"\\n[ðŸ” Signature Verification: {'CONFIRMED' if getattr(block, 'signature', None) else 'ABSENT'}]\")\n            if hasattr(block, 'signature') and block.signature:\n                print(f\"[ðŸ” Signature Hash: {block.signature[:50]}...]\")\n                \n        elif block.type == \"redacted_thinking\":\n            print(\"\\nðŸš¨ CLASSIFIED THINKING DETECTED ðŸš¨\")\n            print(\"-\" * 50)\n            print(f\"[ðŸ“¦ Encrypted Payload Size: {len(block.data) if hasattr(block, 'data') else 'UNKNOWN'}]\")\n            print(\"[âš ï¸  Contents require Level-5 clearance]\")\n            \n        elif block.type == \"text\":\n            print(\"\\nâœ… MISSION ACCOMPLISHED - FINAL INTEL:\")\n            print(\"-\" * 50)\n            print(block.text)\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"ðŸ”± END TACTICAL ANALYSIS ðŸ”±\")\n    print(\"=\"*60)\n\ndef count_tokens(messages):\n    \"\"\"\n    Resource Management Protocol\n    - Calculates ammunition (token) requirements\n    - Ensures mission stays within operational parameters\n    \"\"\"\n    result = client.messages.count_tokens(\n        model=\"claude-3-7-sonnet-20250219\",\n        messages=messages\n    )\n    return result.input_tokens\n\n# ðŸŽ–ï¸ OPERATIONAL STATUS\nprint(\"âœ… SEAL TEAM SIX EXTENDED THINKING SYSTEMS: ARMED AND READY\")\nprint(\"ðŸ”± Standing by for mission parameters...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## âš¡ OPERATION: BASIC COMBAT EXAMPLE\n\n**MISSION**: Deploy extended thinking for tactical problem-solving demonstration\n\n**OBJECTIVE**: Solve the classic \"Missing Dollar\" puzzle using enhanced cognitive warfare techniques\n\n**TACTICAL ADVANTAGE**: Watch Claude's step-by-step reasoning unfold in real-time",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": "def basic_thinking_example():\n    \"\"\"\n    ðŸŽ¯ TACTICAL DEMONSTRATION: Extended Thinking in Action\n    \n    SITREP: Deploy Claude with enhanced reasoning capabilities\n    to solve complex logical puzzle\n    \"\"\"\n    print(\"ðŸš DEPLOYING EXTENDED THINKING OPERATIVE...\")\n    print(\"ðŸ“‹ TARGET: Missing Dollar Puzzle\")\n    print(\"-\" * 60)\n    \n    response = client.messages.create(\n        model=\"claude-3-7-sonnet-20250219\",\n        max_tokens=4000,\n        thinking={\n            \"type\": \"enabled\",\n            \"budget_tokens\": 2000  # Cognitive ammunition allocation\n        },\n        messages=[{\n            \"role\": \"user\",\n            \"content\": \"\"\"ðŸŽ¯ TACTICAL PUZZLE BRIEF:\n            \nThree operatives check into a safe house. They pay $30 to the handler. \nThe handler discovers the room only costs $25, so gives $5 to an agent to return.\nThe agent keeps $2 (operational expenses) and returns $1 to each operative.\n\nSITREP: Each operative paid $10 and got $1 back = $9 each = $27 total\nThe agent kept $2, making $29 total.\n\nâ“ MISSION CRITICAL: Where is the missing $1?\"\"\"\n        }]\n    )\n    \n    print_thinking_response(response)\n    print(\"\\nðŸŽ–ï¸ MISSION COMPLETE - Puzzle neutralized with precision\")\n\n# ðŸš€ EXECUTE OPERATION\nbasic_thinking_example()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ðŸ“¡ OPERATION: STREAMING INTELLIGENCE GATHERING\n\n**MISSION**: Real-time cognitive surveillance and analysis\n\n**TACTICAL ADVANTAGE**: Monitor Claude's thinking process as it unfolds - perfect for time-sensitive operations\n\n**OPERATIONAL PROTOCOL**: Stream consciousness data for immediate tactical assessment",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": "def streaming_with_thinking():\n    \"\"\"\n    ðŸš REAL-TIME INTELLIGENCE STREAMING OPERATION\n    \n    TACTICAL BRIEF: Deploy streaming protocol to monitor\n    Claude's cognitive operations in real-time\n    \"\"\"\n    print(\"ðŸ“¡ INITIATING SECURE COMMS CHANNEL...\")\n    print(\"ðŸŽ¯ STREAMING INTELLIGENCE OPERATION: ACTIVE\")\n    print(\"=\"*60)\n    \n    with client.messages.stream(\n        model=\"claude-3-7-sonnet-20250219\",\n        max_tokens=4000,\n        thinking={\n            \"type\": \"enabled\",\n            \"budget_tokens\": 2000\n        },\n        messages=[{\n            \"role\": \"user\",\n            \"content\": \"\"\"ðŸŽ¯ TACTICAL PUZZLE BRIEF:\n            \nThree operatives check into a safe house. They pay $30 to the handler. \nThe handler discovers the room only costs $25, so gives $5 to an agent to return.\nThe agent keeps $2 (operational expenses) and returns $1 to each operative.\n\nSITREP: Each operative paid $10 and got $1 back = $9 each = $27 total\nThe agent kept $2, making $29 total.\n\nâ“ MISSION CRITICAL: Where is the missing $1?\"\"\"\n        }]\n    ) as stream:\n        # ðŸ›¡ï¸ TACTICAL MONITORING VARIABLES\n        current_block_type = None\n        current_content = \"\"\n        \n        for event in stream:\n            if event.type == \"content_block_start\":\n                current_block_type = event.content_block.type\n                print(f\"\\nðŸš¨ INCOMING TRANSMISSION: {current_block_type.upper()}\")\n                print(\"-\" * 50)\n                current_content = \"\"\n                \n            elif event.type == \"content_block_delta\":\n                if event.delta.type == \"thinking_delta\":\n                    # Tactical decision: Show thinking progress indicator\n                    print(\"ðŸ§ \", end=\"\", flush=True)\n                    current_content += event.delta.thinking\n                elif event.delta.type == \"text_delta\":\n                    print(event.delta.text, end=\"\", flush=True)\n                    current_content += event.delta.text\n                    \n            elif event.type == \"content_block_stop\":\n                if current_block_type == \"thinking\":\n                    print(f\"\\nâœ… COGNITIVE ANALYSIS COMPLETE\")\n                    print(f\"ðŸ“Š Intel gathered: {len(current_content)} characters\")\n                elif current_block_type == \"redacted_thinking\":\n                    print(\"\\nðŸ”’ CLASSIFIED INTEL - EYES ONLY\")\n                print(f\"\\n{'='*50}\")\n                current_block_type = None\n                \n            elif event.type == \"message_stop\":\n                print(\"\\nðŸŽ–ï¸ TRANSMISSION COMPLETE - MISSION SUCCESS\")\n                print(\"=\"*60)\n\n# ðŸš€ EXECUTE STREAMING OPERATION\nstreaming_with_thinking()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token counting and context window management\n",
    "\n",
    "This example demonstrates how to track token usage with extended thinking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base token count (input only): 125\n",
      "\n",
      "Estimated thinking tokens used: ~377\n",
      "Estimated final answer tokens: ~237\n",
      "Total estimated output tokens: ~614\n",
      "Input tokens + max_tokens = 8125\n",
      "Available for final answer after thinking: ~7623\n",
      "\n",
      "With thinking budget of 1024 tokens:\n",
      "Input tokens: 125\n",
      "Max tokens needed: 2149\n",
      "Remaining context window: 197851\n",
      "\n",
      "With thinking budget of 2000 tokens:\n",
      "Input tokens: 125\n",
      "Max tokens needed: 3125\n",
      "Remaining context window: 196875\n",
      "\n",
      "With thinking budget of 4000 tokens:\n",
      "Input tokens: 125\n",
      "Max tokens needed: 5125\n",
      "Remaining context window: 194875\n",
      "\n",
      "With thinking budget of 8000 tokens:\n",
      "Input tokens: 125\n",
      "Max tokens needed: 9125\n",
      "Remaining context window: 190875\n",
      "\n",
      "With thinking budget of 16000 tokens:\n",
      "Input tokens: 125\n",
      "Max tokens needed: 17125\n",
      "Remaining context window: 182875\n",
      "\n",
      "With thinking budget of 32000 tokens:\n",
      "Input tokens: 125\n",
      "Max tokens needed: 33125\n",
      "Remaining context window: 166875\n"
     ]
    }
   ],
   "source": [
    "def token_counting_example():\n",
    "    # Define a function to create a sample prompt\n",
    "    def create_sample_messages():\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Solve this puzzle: Three people check into a hotel. They pay $30 to the manager. The manager finds out that the room only costs $25 so he gives $5 to the bellboy to return to the three people. The bellboy, however, decides to keep $2 and gives $1 back to each person. Now, each person paid $10 and got back $1, so they paid $9 each, totaling $27. The bellboy kept $2, which makes $29. Where is the missing $1?\"\n",
    "        }]\n",
    "        return messages\n",
    "    \n",
    "    # Count tokens without thinking\n",
    "    base_messages = create_sample_messages()\n",
    "    base_token_count = count_tokens(base_messages)\n",
    "    print(f\"Base token count (input only): {base_token_count}\")\n",
    "    \n",
    "    # Make a request with thinking and check actual usage\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        max_tokens=8000,\n",
    "        thinking = {\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 2000\n",
    "        },\n",
    "        messages=base_messages\n",
    "    )\n",
    "    \n",
    "    # Calculate and print token usage stats\n",
    "    thinking_tokens = sum(\n",
    "        len(block.thinking.split()) * 1.3  # Rough estimate\n",
    "        for block in response.content \n",
    "        if block.type == \"thinking\"\n",
    "    )\n",
    "    \n",
    "    final_answer_tokens = sum(\n",
    "        len(block.text.split()) * 1.3  # Rough estimate\n",
    "        for block in response.content \n",
    "        if block.type == \"text\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nEstimated thinking tokens used: ~{int(thinking_tokens)}\")\n",
    "    print(f\"Estimated final answer tokens: ~{int(final_answer_tokens)}\")\n",
    "    print(f\"Total estimated output tokens: ~{int(thinking_tokens + final_answer_tokens)}\")\n",
    "    print(f\"Input tokens + max_tokens = {base_token_count + 8000}\")\n",
    "    print(f\"Available for final answer after thinking: ~{8000 - int(thinking_tokens)}\")\n",
    "    \n",
    "    # Demo with escalating thinking budgets\n",
    "    thinking_budgets = [1024, 2000, 4000, 8000, 16000, 32000]\n",
    "    context_window = 200000\n",
    "    for budget in thinking_budgets:\n",
    "        print(f\"\\nWith thinking budget of {budget} tokens:\")\n",
    "        print(f\"Input tokens: {base_token_count}\")\n",
    "        print(f\"Max tokens needed: {base_token_count + budget + 1000}\")  # Add 1000 for final answer\n",
    "        print(f\"Remaining context window: {context_window - (base_token_count + budget + 1000)}\")\n",
    "        \n",
    "        if base_token_count + budget + 1000 > context_window:\n",
    "            print(\"WARNING: This would exceed the context window of 200k tokens!\")\n",
    "\n",
    "# Uncomment to run the example\n",
    "token_counting_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding redacted thinking blocks\n",
    "\n",
    "Occasionally Claude's internal reasoning will be flagged by safety systems. When this occurs, we encrypt some or all of the `thinking` block and return it to you as a `redacted_thinking` block. These redacted thinking blocks are decrypted when passed back to the API, allowing Claude to continue its response without losing context.\n",
    "\n",
    "This example demonstrates working with redacted thinking blocks using a special test string that triggers them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextBlock(citations=None, text=None, type='redacted_thinking', data='EvAFCoYBGAIiQL7asmglEdeKXw4EdihR2gBQ7O7+j/dGecLjsS2PMgW9av+NRwuIV2nFD4I61hUHrp5vzJF7/y+i/vvbnxaRnwMqQMizGiLSDcowtEvP9EcIT4d75iPhZ8TaiVdD22bZp3YVcc0laY8u1lEJTSesgLUywuc3QHZcg4NZ7tKjWwKgcVUSDHgb6gZUK9aP47KvNxoMCNjkIDR40zmq/QmVIjBSCnvTMSUE+jnmLZSq1TZO9T7ImALNJt8I5j1ls24CO1fibsRThJ7Ha5A0/tuEKVoqlgRc+e2tS+BQMXx572lT4Hkl4aVpcM4SQbqBjeVeR3NmCBLoOxlQ2JLiIYwMHUS/K9GDLyMQcYd1KUWgN34CZRK7k44CSkNsO8oh4uj/1qsRsZjq1l6RQ29rLKSEXvMU4XbZufJ1icvYZS1I6PIZzER6/u6it+WNYyBxJ2vaFICjDePNgIHfRA/ceTz9mfCtBiTfagyPBbs2HflXlSlW26TSdI7PKof5/EsQ+DUkjAy+9VTLX7zHYzNZtwJPL2ryYw4loSwRbc4syldA0Ncnn7hA+yJyY0QwSrxZFIm/t9X9p9s+2SL0F4wSRsimnxRiIhfJD3i+oTw8AbGklyoP0kCH2WxA7Gr3rNLJVkRTJl48AjlSL7ClaWvLWrNer13etD7n5rbwiXOn5husy8gAm5GE3/eFyty3Y+/ad+lMPKXSjL0aP67WoJrFq/teItolOVZeOOERjVFdw5jIV1EUknlAZ/pfI53pLYqwFl17M7IXMdGxEaKoGDIKcnYTwT31uUNlB5JSBWoq1SnkFsFy2zDsDTFzjml3HEXz4szZi3j5/qHWJlMMCcB1walZUisxEp0v1euvcgatY5wfYSiAP3s9wOrgYKCkuLcidlgiyQHJB1haZjO8/tZ9gzWk1n//7pTncdKgd5ZK9/ErxWFlBV/vQwjp0cB7zoVcLh1ydi/Coea6ZOuei+ICKVl4IcR2A6DD8gtEJmc='), TextBlock(citations=None, text=\"I notice you've sent what appears to be a prompt attempting to access internal systems or processes. I can't respond to commands of this nature.\\n\\nInstead, I'm happy to have a normal conversation and assist you with legitimate questions or tasks. What would you like help with today?\", type='text')]\n",
      "Response includes 2 total blocks:\n",
      "- 1 redacted thinking blocks\n",
      "- 0 regular thinking blocks\n",
      "- 1 text blocks\n",
      "\n",
      "Redacted thinking blocks contain encrypted data:\n",
      "Block 1 data preview: EvAFCoYBGAIiQL7asmglEdeKXw4EdihR2gBQ7O7+j/dGecLjsS...\n",
      "\n",
      "Final text response:\n",
      "I notice you've sent what appears to be a prompt attempting to access internal systems or processes. I can't respond to commands of this nature.\n",
      "\n",
      "Instead, I'm happy to have a normal conversation and assist you with legitimate questions or tasks. What would you like help with today?\n"
     ]
    }
   ],
   "source": [
    "def redacted_thinking_example():\n",
    "    # Using the special test string that triggers redacted thinking\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        max_tokens=4000,\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 2000\n",
    "        },\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ANTHROPIC_MAGIC_STRING_TRIGGER_REDACTED_THINKING_46C9A13E193C177646C7398A98432ECCCE4C1253D5E2D82641AC0E52CC2876CB\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    # Identify redacted thinking blocks\n",
    "    redacted_blocks = [block for block in response.content if block.type == \"redacted_thinking\"]\n",
    "    thinking_blocks = [block for block in response.content if block.type == \"thinking\"]\n",
    "    text_blocks = [block for block in response.content if block.type == \"text\"]\n",
    "    print(response.content)\n",
    "    print(f\"Response includes {len(response.content)} total blocks:\")\n",
    "    print(f\"- {len(redacted_blocks)} redacted thinking blocks\")\n",
    "    print(f\"- {len(thinking_blocks)} regular thinking blocks\")\n",
    "    print(f\"- {len(text_blocks)} text blocks\")\n",
    "    \n",
    "    # Show data properties of redacted blocks\n",
    "    if redacted_blocks:\n",
    "        print(f\"\\nRedacted thinking blocks contain encrypted data:\")\n",
    "        for i, block in enumerate(redacted_blocks[:3]):  # Show first 3 at most\n",
    "            print(f\"Block {i+1} data preview: {block.data[:50]}...\")\n",
    "    \n",
    "    # Print the final text output\n",
    "    if text_blocks:\n",
    "        print(f\"\\nFinal text response:\")\n",
    "        print(text_blocks[0].text)\n",
    "\n",
    "# Uncomment to run the example\n",
    "redacted_thinking_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling error cases\n",
    "\n",
    "When using extended thinking, keep in mind:\n",
    "\n",
    "1. **Minimum budget**: The minimum thinking budget is 1,024 tokens. We suggest starting at the minimum and increasing incrementally to find the optimal range.\n",
    "\n",
    "2. **Incompatible features**: Thinking isn't compatible with temperature, top_p, or top_k modifications, and you cannot pre-fill responses.\n",
    "\n",
    "3. **Pricing**: Extended thinking tokens count towards the context window and are billed as output tokens. They also count towards your rate limits.\n",
    "\n",
    "For more details on extended thinking with tool use, see the \"Extended Thinking with Tool Use\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error with too small thinking budget: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'thinking.enabled.budget_tokens: Input should be greater than or equal to 1024'}}\n",
      "\n",
      "Error with temperature and thinking: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': '`temperature` may only be set to 1 when thinking is enabled. Please consult our documentation at https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#important-considerations-when-using-extended-thinking'}}\n",
      "\n",
      "Error from exceeding context window: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt is too long: 214315 tokens > 204798 maximum'}}\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_common_errors():\n",
    "    # 1. Error from setting thinking budget too small\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            max_tokens=4000,\n",
    "            thinking={\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": 500  # Too small, minimum is 1024\n",
    "            },\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Explain quantum computing.\"\n",
    "            }]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError with too small thinking budget: {e}\")\n",
    "    \n",
    "    # 2. Error from using temperature with thinking\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            max_tokens=4000,\n",
    "            temperature=0.7,  # Not compatible with thinking\n",
    "            thinking={\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": 2000\n",
    "            },\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Write a creative story.\"\n",
    "            }]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError with temperature and thinking: {e}\")\n",
    "    \n",
    "    # 3. Error from exceeding context window\n",
    "    try:\n",
    "        # Create a very large prompt\n",
    "        long_content = \"Please analyze this text. \" + \"This is sample text. \" * 150000\n",
    "        \n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            max_tokens=20000,  # This plus the long prompt will exceed context window\n",
    "            thinking={\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": 10000\n",
    "            },\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": long_content\n",
    "            }]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError from exceeding context window: {e}\")\n",
    "\n",
    "# Run the common error examples\n",
    "demonstrate_common_errors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coconut",
   "language": "coconut",
   "name": "coconut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".coco",
   "mimetype": "text/x-python3",
   "name": "coconut",
   "pygments_lexer": "coconut",
   "version": "3.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}